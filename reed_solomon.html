<html>

<head>
  <title>Reed-Solomon Encoding</title>
  <link rel="stylesheet" href="style.css">
</head>

<script>
  MathJax = {
    chtml: {
      displayAlign: 'left',
      scale: 0.8,
    },
  };
  window.addEventListener('load', () => { initPage(); });
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script src="reed_solomon.js"></script>
<script src="page.js"></script>

<body>
  <div id="message-display">
    <span>Message</span>
    <input id="message-input" type="text" value="hello world">

    <span>Bytes \([a_k, \cdots, a_1]\)</span>
    <div>
      <div class="description">
        Encode the message into bytes. Here the string is
        <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a> encoded.
      </div>
      <div class="bytes" id="message-utf8"></div>
    </div>

    <span>\(p(x) = \sum_{j=1}^k a_j x^{j-1}\)</span>
    <div>
      <div class="description">
        Take the series of bytes as representing
        elements in the finite field \(GF(2^8)\). We could encode into
        another finite field but \(GF(2^8)\) corresponds nicely with bytes.
        <br>
        Define a polynomial whose coefficients are the elements in the
        message.
      </div>
      <div class="polynomial" id="message-poly"></div>
    </div>

    <span>\(s(x) = p(x) \cdot x^t - s_r(x) \)</span>
    <div>
      <div class="description">
        In the final encoding, we want the original message to remain intact
        (i.e. a <a href="https://en.wikipedia.org/wiki/Systematic_code">
        systematic code</a>) at the start of the result.
        <br>
        We want \(t\) bytes of redundancy, so shift \(p(x)\) \(t\) times to
        make room for the check symbols.
        <br>
        We will define the valid codewords to be those which are divisible
        by \(g(x)\). To construct a valid encoding, compute:
        <br>
        \(s_r(x) = p(x) \cdot x^t \pmod{g(x)}\)
        <br>
        Then \(s(x) = p(x) \cdot x^t - s_r(x) \) is a valid codeword.
      </div>
      <div class="polynomial" id="message-poly-shifted"></div>
    </div>


    <span>Encoded (hex)</span>
    <span class="bytes" id="message-encoded"></span>

    <span>Recieved (hex)</span>
    <span class="bytes" id="recieved-encoded"></span>

    <span>Recieved \(r(x) = s(x) + e(x)\)</span>
    <div>
      <div class="description">
        Interpret the data we recieve a polynomial \(r(x)\). This data may
        not be the same as the transmited data as it could have been corrupted
        by a unknown errors, which we will call \(e(x)\).
      </div>
      <div class="polynomial" id="recieved-poly"></div>
    </div>

    <span>Syndromes \(S_j = r(\alpha^j) = e(\alpha^j)\)</span>
    <div>
      <div class="description">
        Define \(t\) <em>syndromes</em> where \(r(x)\) is evaluated for each
        root of \(g(x)\), i.e. \(\alpha^j\) where \(0 \le j \lt t\).
        <br>
        For a valid codeword \(c(x)\), we know that \(c(\alpha^j) = 0\) because
        \(g(x)\) divides \(c(x)\) by definition.
        <br>
        Hence \(S_j = s(\alpha^j) + e(\alpha^j) = 0 + e(\alpha^j) = e(\alpha^j)\).
        <br>
        This gives us the nice property that \(S_j\) depends <em>only</em> on
        the error \(e(x)\), and that for a valid codeword \(S_j = 0\).
      </div>
      <div class="polynomial" id="syndromes"></div>
    </div>

    <div>
        \(e(x) = \sum_{k=1}^\nu e_{i_k} x^{i_k}\)
        <br>
        \(X_k = \alpha^{i_k}\)
    </div>
    <div>
      <div class="description">
        \(e(x)\) will only have non-zero terms where there are errors so let
        \(e(x) = \sum_{k=1}^\nu e_{i_k} x^{i_k}\), where:
        <ul>
          <li>\(\nu\) is the (unknown) number of errors</li>
          <li>\(i_k\) is the position of the errors</li>
          <li>\(e_{i_k}\) is the magnitude of the errors</li>
        </ul>
        Define the <em>error locators</em> \(X_k = \alpha^{i_k}\).
        <br>
        Thus \(
          S_j = e(\alpha^j)
              = \sum_{k=1}^\nu e_{i_k} (\alpha^j)^{i_k}
              = \sum_{k=1}^{\nu} e_{i_k} X_k^j
        \)
      </div>
    </div>

    <span>Error Locator \(\Lambda(x) = \prod_{k=1}^\nu (1 - x X_k )\)</span>
    <div>
      <div class="description">
        Define the <em>error locator</em> polynomial
        \(\Lambda(x) = \prod_{k=1}^\nu (1 - x X_k ) = 1 + \Lambda_1 x^1 + \Lambda_2 x^2 + \cdots + \Lambda_\nu x^\nu\)
        <br>
        Combining with \(S_j\) we can
        <a href="https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction#Error_locator_polynomial">derive</a>
        a system of \(\nu\) linear equations:
        \(S_j \Lambda_{\nu} + S_{j+1}\Lambda_{\nu-1} + \cdots + S_{j+\nu-1} \Lambda_1 = - S_{j + \nu} \)
        for \(1 \leq j \leq v\)
        <br>
        If we knew \(\nu\) we could solve this, but we don't. Naively we can
        still solve this by trying values of \(\nu\) from the largest value,
        \(t\), down until the system is solvable. The first value of
        \(\nu\) for which the system is solvable is the number of errors.
        <br>
        The <a href="https://en.wikipedia.org/wiki/Berlekamp%E2%80%93Massey_algorithm">Berlekamp-Massey algorithm</a>
        will do this more efficiently.
      </div>
      <div class="polynomial" id="error-locator"></div>
    </div>

    <span>Error Positions \(i_k\)</span>
    <div>
      <div class="description">
        By construction \(\Lambda (X_{k}^{-1}) = 0\). Thus by determining
        the roots of \(\Lambda(x)\) we can find
        \(i_k = \log_{\alpha}(\alpha^{i_k}) = \log_{\alpha}(X_k)\).
      </div>
      <div id="error-positions"></div>
    </div>

    <span>\(e(x) = \sum_{k=1}^\nu e_{i_k} x^{i_k}\)</span>
    <div>
      <div class="description">
        To find \(e_{i_k}\) we can solve the system of \(\nu\) linear equations
        given by the definition of \(S_j\):
        <br>
        \( S_j = \sum_{k=1}^\nu e_{i_k} (\alpha^j)^{i_k} \) for \(1 \le j \le \nu\)
        <br>
        This is more efficient with the
        <a href="https://en.wikipedia.org/wiki/Forney_algorithm">Forney algorithm</a>:
        <br>
        Define the <em>syndrome polynomial</em>
        \(S(x) = S_0 x^0 + S_1 x^1 + \cdots + S_{\nu} x^{\nu}\)
        <br>
        Define the <em>error evaluator</em> polynomial
        \(\Omega(x) = S(x)\Lambda(x) \pmod{x^{\nu}}\)
        <br>
        Let \(\Lambda'(x) = \sum _{k=1}^{\nu} k \Lambda_i x^{k-1} \) be the
        <a href="https://en.wikipedia.org/wiki/Formal_derivative">formal derivative</a>
        of \(\Lambda(x)\).
        <br>
        Then \(e_{i_k}=-{\frac {\Omega (X_{k}^{\nu})}{\Lambda '(X_{k}^{-1})}}\)
      </div>
      <div class="polynomial" id="correction-poly"></div>
    </div>

    <span>Decoded Polynomial \(s'(x) = \lfloor \frac{r(x) - e(x)}{x^t} \rfloor \)</span>
    <span class="polynomial" id="decoded-poly"></span>

    <span>Decoded Bytes</span>
    <span class="bytes" id="decoded-utf8"></span>

    <span>Result</span>
    <span id="decoded-message"></span>
  </div>
  <div id="codec-display">
    <div>
      # Check symbols \(t = \)
      <input type="number" value="10">
    </div>

    <div>
      Field \( GF(2^8) \)
    </div>

    <div>
      Primitive polynomial \( = z^8+z^4+z^3+z^2+1 = \texttt{0x11d} \)
    </div>

    <div>
      Generator element \(\alpha = \texttt{02}\)
    </div>

    <div>Generator polynomial</div>
    <div>
      $$ g(x) = \prod_{j=0}^{t-1} (x - \alpha^j) $$
    </div>
  </div>
</body>

</html>
